{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9c8806d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from lib2to3.pytree import convert\n",
    "import pandas\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#from tqdm import tqdm\n",
    "\n",
    "os.chdir(\"/Users/pbenson/Documents/IOH project/\")\n",
    "\n",
    "txn_dirPath = 'Data/'\n",
    "\n",
    "\n",
    "txn_converter = {'TXN - Transaction Type': str,\n",
    "                 'TXN - Transaction Date': str,\n",
    "                 'TXN - Item ID': str,\n",
    "                 'TXN - Qty': float,\n",
    "                 'TXN - Total Cost': float}\n",
    "\n",
    "transaction_col = ['TXN - Transaction Type', 'TXN - Transaction Date',\n",
    "                   'TXN - Item ID', 'TXN - Qty', 'TXN - Total Cost', 'TXN - Adjust Type']\n",
    "\n",
    "out_types = ('051', '054', '030', '031')\n",
    "positive_types = (41, 22, 24, 50, 10, 20)\n",
    "drop_types = ('060', '053', '052', '012', '001', '042')\n",
    "\n",
    "#date = '2021-12-31 23:59:59'\n",
    "\n",
    "def get_lof_csv(directory):\n",
    "    lof = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.csv'):\n",
    "            lof.append(directory + file)\n",
    "            print(\"Read file {}\".format(file))\n",
    "    return lof\n",
    "\n",
    "def read_csv_to_df(lof, converter):\n",
    "    print(\"Converting to pandas dataframe\")\n",
    "\n",
    "    dataframe = pandas.DataFrame()\n",
    "\n",
    "    # More efficient way to do this: pd.concat\n",
    "    next_txns = []\n",
    "    for f in lof:\n",
    "        next_txn = pandas.read_csv(f, converters=converter, encoding= 'unicode_escape')\n",
    "        next_txns.append(next_txn)\n",
    "        #dataframe = dataframe.append(next_txn, ignore_index=True)\n",
    "        print(f + ' is appened')\n",
    "    dataframe = pandas.concat(next_txns, ignore_index=True)\n",
    "    return dataframe\n",
    "\n",
    "def handle_I_D(txn_df):\n",
    "    txn_df['TXN - Qty'] = np.where(txn_df['TXN - Adjust Type'] == 'D', 0 - abs(txn_df['TXN - Qty']),\n",
    "                                   txn_df['TXN - Qty'])\n",
    "    txn_df['TXN - Qty'] = np.where(txn_df['TXN - Adjust Type'] == 'M', 0 - abs(txn_df['TXN - Qty']),\n",
    "                                   txn_df['TXN - Qty'])\n",
    "    txn_df['TXN - Total Cost'] = np.where(txn_df['TXN - Adjust Type'] == 'D', 0 - abs(txn_df['TXN - Total Cost']),\n",
    "                                          txn_df['TXN - Total Cost'])\n",
    "    txn_df['TXN - Total Cost'] = np.where(txn_df['TXN - Adjust Type'] == 'M', 0 - abs(txn_df['TXN - Total Cost']),\n",
    "                                          txn_df['TXN - Total Cost'])\n",
    "    \n",
    "    \n",
    "    for t_type in out_types: \n",
    "        txn_df.loc[txn_df['TXN - Transaction Type'] == t_type, 'TXN - Qty'] = 0 - abs(txn_df['TXN - Qty'])\n",
    "        txn_df.loc[txn_df['TXN - Transaction Type'] == t_type, 'TXN - Total Cost'] = 0 - abs(txn_df['TXN - Total Cost'])\n",
    "\n",
    "    for t_type in drop_types:\n",
    "        txn_df.loc[txn_df['TXN - Transaction Type'] == t_type, 'TXN - Qty'] = 0 \n",
    "        txn_df.loc[txn_df['TXN - Transaction Type'] == t_type, 'TXN - Total Cost'] = 0\n",
    "    \n",
    "    # Trust Anni's Code â€“ it has already been validated.\n",
    "\n",
    "    # We don't want to drop columns.\n",
    "    #txn_df = txn_df.drop(columns=['TXN - Transaction Type', 'TXN - Adjust Type'])\n",
    "    return txn_df\n",
    "\n",
    "def read_txn_by_date(txn_df, date):\n",
    "    txn_df = txn_df.loc[txn_df['TXN - Transaction Date'] < date]\n",
    "    #txn_df = txn_df.drop(columns=['TXN - Transaction Date'])\n",
    "    # We don't want to drop the Transaction Date column.\n",
    "    return txn_df\n",
    "\n",
    "def sum_by_date(txn_df, date):\n",
    "    txn_df = txn_df.loc[txn_df['TXN - Transaction Date'] < date]\n",
    "    #txn_df = txn_df.drop(columns=['TXN - Transaction Date'])\n",
    "    # We don't want to drop the Transaction Date column.\n",
    "    return txn_df[\"TXN - Total Cost\"].sum()\n",
    "\n",
    "def sku_running_total(txn_df: pandas.DataFrame, item_sku: str) -> float:\n",
    "    return txn_df.loc[txn_df['TXN - Item ID'] == item_sku, ('TXN - Qty', 'TXN - Transaction Type')]\n",
    "\n",
    "def thousand_places(number):\n",
    "    # Simple function for formatting large number outputs\n",
    "    number = round(number, 2)\n",
    "    return \"{:,}\".format(number)\n",
    "\n",
    "def validate_skus(txn_df):\n",
    "    # Process txn_df into sku_sum dataframe\n",
    "    sku_sums = txn_df.groupby(['TXN - Item ID'])['TXN - Qty'].sum()\n",
    "    \n",
    "    # Read in and process valid SKU's\n",
    "    valid_sku_sums_df = pandas.read_csv('Data/Valid_End_Quantities.csv')\n",
    "    \n",
    "    valid_sku_sums_df.columns = valid_sku_sums_df.iloc[0] \n",
    "    valid_sku_sums_df = valid_sku_sums_df[1:]\n",
    "    \n",
    "    valid_sku_sums_df[\"IOH - Qty On Hand\"] = pandas.to_numeric(valid_sku_sums_df[\"IOH - Qty On Hand\"])\n",
    "    valid_sku_sums_df.rename(columns={'IOH - Item ID':'TXN - Item ID'}, inplace=True)\n",
    "    \n",
    "    valid_sku_sums = valid_sku_sums_df.groupby(['TXN - Item ID'])['IOH - Qty On Hand'].sum().to_frame()\n",
    "    \n",
    "    \n",
    "    # Merge SKU sums dataframes\n",
    "    merged_sku_sums = valid_sku_sums.join(other=sku_sums, on='TXN - Item ID')\n",
    "    merged_sku_sums.reset_index(inplace=True)\n",
    "    merged_sku_sums.rename(columns={'index':'TXN - Item ID'}, inplace=True)\n",
    "    \n",
    "    merged_sku_sums['TXN - Qty'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Calculate difference\n",
    "    merged_sku_sums['Qty Difference'] = merged_sku_sums['IOH - Qty On Hand'] - merged_sku_sums['TXN - Qty']\n",
    "    \n",
    "    return merged_sku_sums\n",
    "\n",
    "def get_valid_percent(merged_skus):\n",
    "    return (len(merged_skus) - len(merged_skus.loc[merged_skus['Qty Difference'] != 0])) / len(merged_skus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e731c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file PL_INVENTORY_TRANSACTIONS_2009_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2019_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2020_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2006_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2016_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2012_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2013_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2010_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2017_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2007_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2013_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2012_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2011_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2018_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2008_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2011_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2005_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2015_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2013_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2010_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2021_Q1.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2021_Q3.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2008_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2018_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2019_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2009_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2021_Q2.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2019_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2009_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2008_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2018_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2010_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2014_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2012_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2021_Q4.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2011_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2017_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2007_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2014_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2004_1Hx.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2015_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2005_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2011_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2018_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2008_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2009_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2019_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2020_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2006_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2016_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2015_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2005_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2004_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2014_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2010_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2020_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2007_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2017_Q2x.csv\n",
      "Read file 2021_Q1.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2014_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2004_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2012_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2016_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2006_Q3x.csv\n",
      "Read file ANNI_INVENTORY_TRANSACTIONS.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2016_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2006_Q2x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2005_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2015_Q4x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2013_Q1x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2007_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2017_Q3x.csv\n",
      "Read file PL_INVENTORY_TRANSACTIONS_2020_Q2x.csv\n",
      "Converting to pandas dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (33,40,50,54,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2009_Q4x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,33,36,40,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2019_Q4x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,33,36,40,54,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2020_Q1x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (44,50) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2006_Q1x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (3,6,19,20,33,56,57,58,67,69,70) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2016_Q1x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,44) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2012_Q3x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2013_Q2x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (40,44,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2010_Q4x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (44) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2017_Q1x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (3,17,18,19,33,40,44,47,48,50,58,59,67,70,71,73,75) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2007_Q1x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2013_Q3x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,44,50) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2012_Q2x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2011_Q4x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2018_Q4x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2008_Q4x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2011_Q3x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2005_Q1x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2015_Q1x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2013_Q4x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (33,50,54) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2010_Q2x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,33,40,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2021_Q1.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,36,40,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2021_Q3.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2008_Q3x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2018_Q3x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2019_Q2x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (33,44,54) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2009_Q2x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2021_Q2.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2019_Q3x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (33,40,54,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2009_Q3x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2008_Q2x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (3,6,19,20,36,40,44,47,48,54,56,57,58,59,66,67,69,70) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2018_Q2x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (3,19,33,44,54,58,67) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2010_Q3x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,40,44,50,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2014_Q1x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2012_Q4x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2021_Q4.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (33,44) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2011_Q2x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,40,44,59,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2017_Q4x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (40,44,50,59,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2007_Q4x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2014_Q2x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (3,6,17,18,19,20,27,33,40,44,47,48,56,57,58,59,67,69,70,73,75) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2004_1Hx.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,33,44,54) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2015_Q3x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (40,44,50,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2005_Q3x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2011_Q1x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,33,36,40,59,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2018_Q1x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2008_Q1x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2009_Q1x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2019_Q1x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2020_Q4x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (3,6,19,20,27,33,40,44,47,48,50,56,57,58,59,67,69,70,71,73,75) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2006_Q4x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,40,44,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2016_Q4x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2015_Q2x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2005_Q2x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (3,6,19,20,33,40,44,56,57,58,59,67,69,70) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2004_Q3x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2014_Q3x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (33,44,50,54) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2010_Q1x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,33,36,40,50,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2020_Q3x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,40,44,50,59,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2007_Q2x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2017_Q2x.csv is appened\n",
      "Data/CSV_Files/2021_Q1.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2014_Q4x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2004_Q4x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2012_Q1x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2016_Q3x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (36,44,50,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2006_Q3x.csv is appened\n",
      "Data/CSV_Files/ANNI_INVENTORY_TRANSACTIONS.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,40,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2016_Q2x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,44,50,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2006_Q2x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,40,50,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2005_Q4x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2015_Q4x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (3,17,19,21,33,44,47,48,50,58,67) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2013_Q1x.csv is appened\n",
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2007_Q3x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,36,40,44,59,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2017_Q3x.csv is appened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/445560429.py:1: DtypeWarning: Columns (19,33,36,40,44,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/CSV_Files/PL_INVENTORY_TRANSACTIONS_2020_Q2x.csv is appened\n",
      "Handling ID\n",
      "Balance for 00250052:\n",
      "Sum: 2630.0\n",
      "Balance for 42082077: 71.0\n",
      "Balance for 00250066: 2146.0\n",
      "Validating SKU Counts\n",
      "0.9880386443796964\n",
      "Dumping SKU counts to dataframe\n"
     ]
    }
   ],
   "source": [
    "txn_df = read_csv_to_df(get_lof_csv(txn_dirPath + \"CSV_Files/\"), txn_converter)\n",
    "\n",
    "\n",
    "dataframe = txn_df.copy(deep = True) \n",
    "\n",
    "# # drop duplication\n",
    "dataframe = dataframe.drop_duplicates()\n",
    "# # filter dataframe\n",
    "dataframe = dataframe.loc[dataframe['TXN - Transaction Type'].isin(['010', '020', '022', '024', '030', '031', '041', '050', '051', '054'])]\n",
    "#dataframe\n",
    "\"\"\"\n",
    "\n",
    "full_dataframe_path = \"Data/full_dataframe.tsv\"\n",
    "\n",
    "# Tab-separated is a better bet than csv.\n",
    "print(\"Reading Dataframe\")\n",
    "dataframe = pandas.read_csv(full_dataframe_path, converters=txn_converter, sep=\"\\t\")\n",
    "\n",
    "print(dataframe.head(10))\n",
    "\"\"\"\n",
    "\n",
    "# NOTE: this program seems to work fine when building the dataframe from scratch (using the csv files). \n",
    "# However, it fails when trying to build from the exported version of the same dataframe (full_dataframe.tsv). \n",
    "# I suspect there is slight deviation during export/import\n",
    "\n",
    "#print(\"Filtering by date\")\n",
    "#dataframe = read_txn_by_date(dataframe,date)\n",
    "#print(dataframe.loc[dataframe['TXN - Transaction Type'] == '031', 'TXN - Qty'])\n",
    "print(\"Handling ID\")\n",
    "\n",
    "dataframe = handle_I_D(dataframe)\n",
    "#print(dataframe.loc[dataframe['TXN - Transaction Type'] == '031', 'TXN - Qty'])\n",
    "#dataframe.loc[dataframe['TXN - Transaction Type'] == '031', 'TXN - Qty'] = 0 - abs(dataframe['TXN - Qty'])\n",
    "#print(dataframe.loc[dataframe['TXN - Transaction Type'] == '031', 'TXN - Qty'])\n",
    "\n",
    "\n",
    "print(\"Balance for 00250052:\")\n",
    "print(\"Sum:\", sku_running_total(dataframe, \"00250052\")['TXN - Qty'].sum())\n",
    "\n",
    "print(\"Balance for 42082077:\", sku_running_total(dataframe, \"42082077\")['TXN - Qty'].sum())\n",
    "\n",
    "print(\"Balance for 00250066:\", sku_running_total(dataframe, \"00250066\")['TXN - Qty'].sum())\n",
    "\n",
    "\n",
    "# Process: \n",
    "# - load all csv's \n",
    "# - Deep copy/drop duplicates\n",
    "# - Run new handle_I_D function, don't filter by date\n",
    "# - Run sku_running_total\\['TXN-Qty'\\].sum()\n",
    "\n",
    "### Dump SKU Quantities to csv\n",
    "\n",
    "# TODO for 1/28/22: Get end quantities for every SKU.\n",
    "\n",
    "sku_counts = dataframe.groupby(['TXN - Item ID'])['TXN - Qty'].sum()\n",
    "\n",
    "print(\"Validating SKU Counts\")\n",
    "print(get_valid_percent(validate_skus(dataframe)))\n",
    "\n",
    "print(\"Dumping SKU counts to dataframe\")\n",
    "#sku_counts.to_csv(\"Data/unique_sku_counts.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af85c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Updated_Total_Cost'] = dataframe['TXN - Qty'] * dataframe['TXN - Avg Matl Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06b516cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-619.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.groupby('TXN - Item ID')['TXN - Qty'].sum().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e67526f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Value of Inventory On Hand: 65,871,372.24\n"
     ]
    }
   ],
   "source": [
    "print('Total Value of Inventory On Hand:', thousand_places(sum(dataframe.groupby('TXN - Item ID')['Updated_Total_Cost'].sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b90ef1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Value of Inventory On Hand: 65,881,211.46\n"
     ]
    }
   ],
   "source": [
    "# This script uses the old Total Cost\n",
    "print('Total Value of Inventory On Hand:', thousand_places(sum(dataframe.groupby('TXN - Item ID')['TXN - Total Cost'].sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfb9f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_ioh_value(txn_df):\n",
    "    txn_df = handle_I_D(txn_df)\n",
    "    \n",
    "    txn_df['Updated_Total_Cost'] = txn_df['TXN - Qty'] * txn_df['TXN - Avg Matl Cost']\n",
    "    return sum(txn_df.groupby('TXN - Item ID')['Updated_Total_Cost'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6eccc",
   "metadata": {},
   "source": [
    "Now to get this by date. This should be a simple filtering operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "329ca8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_date = dataframe['TXN - Transaction Date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "490ad601",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_date_date = datetime.strptime(ex_date, '%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5fd7b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009/10/01\n",
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "print(ex_date)\n",
    "print(type(ex_date_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31b1736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-10-01\n"
     ]
    }
   ],
   "source": [
    "bad_date = '1/10/2009'\n",
    "bad_date_formatted = datetime.strptime(bad_date, '%d/%m/%Y')\n",
    "print(bad_date_formatted.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3c436cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ioh_by_date(txn_df, filter_date):\n",
    "    # Assume date is in format 'm d Y'\n",
    "    filter_date_formatted = datetime.strptime(filter_date, '%m/%d/%Y')\n",
    "    \n",
    "    # Filter by date. Convert txn_df['TXN - Transaction Date'] and 'filter_date' to a usable date format\n",
    "    txn_df['TXN - Transaction Date'] = pandas.to_datetime(txn_df['TXN - Transaction Date'])\n",
    "    \n",
    "    txn_df_filtered = txn_df.loc[txn_df['TXN - Transaction Date'] < filter_date_formatted]\n",
    "    \n",
    "    # Call total_ioh_value\n",
    "    \n",
    "    return total_ioh_value(txn_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd3443aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/2815660484.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  txn_df['Updated_Total_Cost'] = txn_df['TXN - Qty'] * txn_df['TXN - Avg Matl Cost']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66308140.855925396"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ioh_by_date(dataframe, '12/31/2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e800ce25",
   "metadata": {},
   "source": [
    "TODO: Implement a caching system to speed up IOH by date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c576ec0c",
   "metadata": {},
   "source": [
    "## Cached Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c4720e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txn_df is the dataframe, date_list is a list of strings in m/d/Y date format\n",
    "def get_ioh_multiple_dates(txn_df, date_list):\n",
    "    ioh_by_day = {}\n",
    "    \n",
    "    for i in range(len(date_list)):\n",
    "        date_list[i] = datetime.strptime(date_list[i], '%m/%d/%Y')\n",
    "        #print(type(date))\n",
    "    # Sort date_list\n",
    "    start_date = datetime.strptime('1/1/2004', '%m/%d/%Y')\n",
    "    \n",
    "    date_list.sort()\n",
    "    \n",
    "    # Convert dataframe date column to datetime.\n",
    "    txn_df['TXN - Transaction Date'] = pandas.to_datetime(txn_df['TXN - Transaction Date'])\n",
    "    \n",
    "    # Calculate IOH for the first date. This will become the basis for the subsequent calculations.\n",
    "    txn_df_filtered = txn_df.loc[txn_df['TXN - Transaction Date'] < date_list[0]]\n",
    "    \n",
    "    # Call total_ioh_value\n",
    "    ioh_by_day[date_list[0].strftime('%m/%d/%Y')] = total_ioh_value(txn_df_filtered)\n",
    "    \n",
    "    # Iterate through the rest of the dates\n",
    "    for i in range(1, len(date_list)):\n",
    "        #print(date_list[i], date_list[i-1])\n",
    "        filtered_df = txn_df.loc[(txn_df['TXN - Transaction Date'] < date_list[i]) & (txn_df['TXN - Transaction Date'] >= date_list[i-1])]\n",
    "        \n",
    "        ioh_by_day[date_list[i].strftime('%m/%d/%Y')] = ioh_by_day[date_list[i-1].strftime('%m/%d/%Y')] + total_ioh_value(filtered_df)\n",
    "    \n",
    "    return ioh_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "40fb3d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/2815660484.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  txn_df['Updated_Total_Cost'] = txn_df['TXN - Qty'] * txn_df['TXN - Avg Matl Cost']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-01-01 00:00:00 2005-01-01 00:00:00\n",
      "2009-01-01 00:00:00 2006-01-01 00:00:00\n",
      "{'01/01/2005': 51601952.5013997, '01/01/2006': 52600313.7322997, '01/01/2009': 62402307.25749953}\n"
     ]
    }
   ],
   "source": [
    "print(get_ioh_multiple_dates(dataframe, ['1/1/2005', '1/1/2006', '1/1/2009']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "102f4d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/2815660484.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  txn_df['Updated_Total_Cost'] = txn_df['TXN - Qty'] * txn_df['TXN - Avg Matl Cost']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-10-01 00:00:00 2005-01-01 00:00:00\n",
      "{'01/01/2005': 51601952.5013997, '10/01/2006': 56253690.23229969}\n"
     ]
    }
   ],
   "source": [
    "print(get_ioh_multiple_dates(dataframe, ['1/1/2005', '10/1/2006']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fd1ccd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/2815660484.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  txn_df['Updated_Total_Cost'] = txn_df['TXN - Qty'] * txn_df['TXN - Avg Matl Cost']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-01-01 00:00:00 2005-01-01 00:00:00\n",
      "2009-01-01 00:00:00 2006-01-01 00:00:00\n",
      "2020-03-01 00:00:00 2009-01-01 00:00:00\n",
      "2021-01-01 00:00:00 2020-03-01 00:00:00\n",
      "{'01/01/2005': 51601952.5013997, '01/01/2006': 52600313.7322997, '01/01/2009': 62402307.25749953, '03/01/2020': 69248771.94670324, '01/01/2021': 66471469.685715236}\n"
     ]
    }
   ],
   "source": [
    "print(get_ioh_multiple_dates(dataframe, ['1/1/2005', '1/1/2006', '1/1/2009', '3/1/2020', '1/1/2021']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1359ddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/2815660484.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  txn_df['Updated_Total_Cost'] = txn_df['TXN - Qty'] * txn_df['TXN - Avg Matl Cost']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69248771.94670354\n"
     ]
    }
   ],
   "source": [
    "print(get_ioh_by_date(dataframe, '3/1/2020'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e383e875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/2815660484.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  txn_df['Updated_Total_Cost'] = txn_df['TXN - Qty'] * txn_df['TXN - Avg Matl Cost']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66471469.685715325\n"
     ]
    }
   ],
   "source": [
    "print(get_ioh_by_date(dataframe, '1/1/2021'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365923cd",
   "metadata": {},
   "source": [
    "David wants a list of the numbers by the end of the month since 2004 (Use 1st of every month because it's exclusive). Dump this to txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9d23da02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/z_zg2ww102j_zl0j1rp57xxcwgxbxw/T/ipykernel_41865/2815660484.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  txn_df['Updated_Total_Cost'] = txn_df['TXN - Qty'] * txn_df['TXN - Avg Matl Cost']\n"
     ]
    }
   ],
   "source": [
    "months_since_2004 = []\n",
    "\n",
    "for i in range(2004, 2021):\n",
    "    for j in range(1, 13):\n",
    "        months_since_2004.append(\"{}/1/{}\".format(j, i))\n",
    "\n",
    "months_since_2004.append('1/1/2021')\n",
    "    \n",
    "all_months_dict = get_ioh_multiple_dates(dataframe, months_since_2004)\n",
    "\n",
    "months_df = pandas.DataFrame.from_dict({'date': all_months_dict.keys(), 'Inventory On Hand value': all_months_dict.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e91ffa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Inventory On Hand value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>03/01/2020</td>\n",
       "      <td>6.924877e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  Inventory On Hand value\n",
       "194  03/01/2020             6.924877e+07"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months_df.loc[months_df['date'] == '03/01/2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d4192be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 44497395.648,\n",
       " 44218436.629,\n",
       " 43674590.13,\n",
       " 43634260.945,\n",
       " 44606822.211,\n",
       " 44653207.588,\n",
       " 45823902.181,\n",
       " 50625216.698,\n",
       " 51601952.501,\n",
       " 47888841.688,\n",
       " 48817904.839,\n",
       " 50043983.091,\n",
       " 50246813.429,\n",
       " 50983549.543,\n",
       " 51652321.213,\n",
       " 50981645.151,\n",
       " 51882555.173,\n",
       " 52348325.406,\n",
       " 52717791.18,\n",
       " 53560209.513,\n",
       " 52600313.732,\n",
       " 54291354.663,\n",
       " 54190892.877,\n",
       " 54460555.557,\n",
       " 55075677.864,\n",
       " 55191766.249,\n",
       " 55085270.82,\n",
       " 55018767.264,\n",
       " 55659741.022,\n",
       " 56253690.232,\n",
       " 56548545.858,\n",
       " 56990752.92,\n",
       " 57313874.919,\n",
       " 58719939.051,\n",
       " 59954769.885,\n",
       " 60800265.648,\n",
       " 60848889.693,\n",
       " 59877924.888,\n",
       " 61649302.87,\n",
       " 61670314.386,\n",
       " 62362704.324,\n",
       " 64154109.688,\n",
       " 63569107.131,\n",
       " 63740193.244,\n",
       " 63572930.487,\n",
       " 63211785.522,\n",
       " 62439093.102,\n",
       " 62940078.856,\n",
       " 62287800.278,\n",
       " 62033136.731,\n",
       " 62828405.926,\n",
       " 62555696.901,\n",
       " 62753340.996,\n",
       " 61542992.691,\n",
       " 61578310.34,\n",
       " 61849214.827,\n",
       " 62402307.257,\n",
       " 62626662.407,\n",
       " 62495653.898,\n",
       " 62402942.687,\n",
       " 62431691.137,\n",
       " 62570658.969,\n",
       " 64057899.862,\n",
       " 63100395.804,\n",
       " 64064458.727,\n",
       " 63362649.855,\n",
       " 63269447.284,\n",
       " 63727092.947,\n",
       " 63655533.247,\n",
       " 63874972.265,\n",
       " 63818223.059,\n",
       " 63687669.107,\n",
       " 63669493.45,\n",
       " 63856593.208,\n",
       " 64545607.272,\n",
       " 65102525.067,\n",
       " 65756433.261,\n",
       " 65559174.668,\n",
       " 65416700.68,\n",
       " 66853520.847,\n",
       " 67084067.848,\n",
       " 66567231.841,\n",
       " 67384759.052,\n",
       " 66898094.884,\n",
       " 67249232.917,\n",
       " 67403289.196,\n",
       " 68760518.289,\n",
       " 68363263.018,\n",
       " 68415411.89,\n",
       " 68984280.871,\n",
       " 69100032.889,\n",
       " 69180178.671,\n",
       " 70019917.015,\n",
       " 76164591.882,\n",
       " 75641444.572,\n",
       " 74910700.613,\n",
       " 74497168.934,\n",
       " 74770902.111,\n",
       " 75606089.519,\n",
       " 69481007.044,\n",
       " 68832443.618,\n",
       " 68846607.012,\n",
       " 68738216.39,\n",
       " 67357129.342,\n",
       " 67800933.312,\n",
       " 67201551.081,\n",
       " 66886909.151,\n",
       " 67156696.647,\n",
       " 66806633.969,\n",
       " 66261561.72,\n",
       " 66164218.201,\n",
       " 65322336.219,\n",
       " 67458443.087,\n",
       " 66180995.908,\n",
       " 65625506.763,\n",
       " 64937359.856,\n",
       " 62729513.069,\n",
       " 64719776.803,\n",
       " 62159260.559,\n",
       " 61461760.679,\n",
       " 60901690.006,\n",
       " 61253833.001,\n",
       " 61675498.195,\n",
       " 61264170.964,\n",
       " 60891848.703,\n",
       " 60197464.739,\n",
       " 59979323.096,\n",
       " 59915743.292,\n",
       " 61161823.894,\n",
       " 60826604.496,\n",
       " 60615521.72,\n",
       " 61086484.997,\n",
       " 61486352.508,\n",
       " 62350379.453,\n",
       " 62473262.365,\n",
       " 61868716.881,\n",
       " 62084216.988,\n",
       " 61841906.222,\n",
       " 61888742.106,\n",
       " 62756631.091,\n",
       " 62998168.578,\n",
       " 63519126.466,\n",
       " 62938047.711,\n",
       " 62965639.172,\n",
       " 63322825.111,\n",
       " 62955718.025,\n",
       " 64190040.135,\n",
       " 62850093.018,\n",
       " 60818029.171,\n",
       " 60644227.667,\n",
       " 60829567.165,\n",
       " 61237060.361,\n",
       " 61828559.746,\n",
       " 62081848.416,\n",
       " 62349896.211,\n",
       " 63209210.107,\n",
       " 63802022.646,\n",
       " 63699419.402,\n",
       " 62976675.185,\n",
       " 62845177.919,\n",
       " 63269208.037,\n",
       " 57853426.555,\n",
       " 59663412.25,\n",
       " 61385468.894,\n",
       " 63833123.976,\n",
       " 64138279.531,\n",
       " 65078097.03,\n",
       " 67232583.806,\n",
       " 67840261.6,\n",
       " 69894017.97,\n",
       " 69732794.623,\n",
       " 70217804.867,\n",
       " 71181563.473,\n",
       " 71609335.837,\n",
       " 71340190.714,\n",
       " 71288225.395,\n",
       " 72285707.983,\n",
       " 71773648.885,\n",
       " 71032724.055,\n",
       " 70295843.801,\n",
       " 69814820.727,\n",
       " 69961409.073,\n",
       " 70112324.636,\n",
       " 69744599.459,\n",
       " 69428939.161,\n",
       " 69227669.483,\n",
       " 69466307.826,\n",
       " 70309860.117,\n",
       " 70227629.749,\n",
       " 69290444.857,\n",
       " 69248771.947,\n",
       " 67408467.12,\n",
       " 65219513.378,\n",
       " 65016147.585,\n",
       " 65052070.233,\n",
       " 64816339.208,\n",
       " 65108173.355,\n",
       " 64796769.675,\n",
       " 65001593.435,\n",
       " 65792514.472,\n",
       " 66471469.686]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months_df = months_df.round(decimals=3)\n",
    "list(months_df['Inventory On Hand value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a3730c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "months_df.to_csv('/Users/pbenson/Documents/IOH project/IOH_by_month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dbad43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
